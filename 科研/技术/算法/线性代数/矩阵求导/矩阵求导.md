# [矩阵求导](https://www.cnblogs.com/pinard/p/10750718.html)

## 矩阵向量求导引入

向量对标量的求导，实质上是向量中每个分量分别对标量求导，如下表示
$$
\frac{\part\mathbf{y}}{\part x}
$$
$m$维向量$\mathbf{y}$对标量$x$求导，结果将是一个$m$维向量，这个向量是行向量或者列向量都可以

## 求导布局

为了解决矩阵向量求导不一致的问题，我们引入了求导布局的概念——分子布局和分母布局

- 分子布局

  求导结果的维度以分子为主，如果$\mathbf{y}$是一个列向量，那么的话$\frac{\part\mathbf{y}}{\part x}$的结果也是一个列向量

- 分母布局

  求导结果的维度以分母为主；如果分母是标量，那么就是分子布局的转置

如此我们能够确定**标量对于矩阵或者向量**还有**矩阵或者向量对于标量**求导的情况

接下来是向量对于向量的求导

## [定义法 标量对向量求导](https://www.cnblogs.com/pinard/p/10773942.html)

标量对向量中的每个值分别进行求导

求解$\frac{\part \mathbf x^T\mathbf A\mathbf x}{\part\mathbf x}$

我们对$\mathbf x$的第$k$个分量求导如下
$$
\frac{\part \mathbf x^T\mathbf A\mathbf x}{\part x_k}=\frac{\part\sum_{i=1}^n\sum_{j=1}^nx_iA_{ij}x_j}{\part x_k}=\sum_{i=1}^nA_{ki}x_i+\sum_{i=1}^nA_{ik}x_i
$$
我们将这若干个分量合并
$$
\frac{\part \mathbf x^T\mathbf A\mathbf x}{\part \mathbf x}=\mathbf A\mathbf x+\mathbf A^T\mathbf x
$$

## 定义法 标量对矩阵求导

求解$\frac{\part \mathbf a^T\mathbf X\mathbf b}{\part\mathbf X}$

我们对矩阵$\mathbf X$的元素$\mathbf X_{ij}$求导
$$
\frac{\part \mathbf a^T\mathbf X\mathbf b}{\part X_{ij}}=\frac{\part\sum_{p=1}^{m}\sum_{q=1}^na_pX_{pq}b_q}{X_{ij}}=a_ib_j
$$
因此求导的结果为
$$
\frac{\part \mathbf a^T\mathbf X\mathbf b}{\part\mathbf X}=\mathbf a\mathbf b^T
$$

## 定义法 向量对向量求导

实际上和以上两者相同，将两个向量中的元素两两拿出分别求导，即可得到求导结果

- 向量对向量求导 雅可比矩阵 梯度矩阵

  我们假设存在一个$m$维的列向量$\mathbf y$以及一个$n$维的列向量$\mathbf x$
  $$
  \mathbf x=\begin{bmatrix}
  x_1\\
  x_2\\
  \ldots\\
  x_n
  \end{bmatrix},
  \mathbf y=\begin{bmatrix}
  y_1\\
  y_2\\
  \ldots\\
  y_m
  \end{bmatrix}
  $$
  > 我们能够使用$\frac{\part\mathbf y}{\part\mathbf x}$来定义雅可比矩阵
  > $$
  > \frac{\part\mathbf y}{\part\mathbf x}=\begin{bmatrix}
  > \frac{\part y_1}{\part x_1}&\frac{\part y_1}{\part x_x}&\ldots&\frac{\part y_1}{\part x_n}\\
  > \frac{\part y_2}{\part x_1}&\frac{\part y_2}{\part x_x}&\ldots&\frac{\part y_2}{\part x_n}\\
  > \vdots&\vdots&\ddots&\vdots\\
  > \frac{\part y_m}{\part x_1}&\frac{\part y_m}{\part x_x}&\ldots&\frac{\part y_m}{\part x_n}\\
  > \end{bmatrix}
  > $$
  > 或者使用$\frac{\part\mathbf y}{\part\mathbf x}^T$来定义梯度矩阵
  > $$
  > \frac{\part\mathbf y}{\part\mathbf x}^T=\begin{bmatrix}
  > \frac{\part y_1}{\part x_1}&\frac{\part y_2}{\part x_1}&\ldots&\frac{\part y_m}{\part x_1}\\
  > \frac{\part y_1}{\part x_2}&\frac{\part y_2}{\part x_2}&\ldots&\frac{\part y_m}{\part x_2}\\
  > \vdots&\vdots&\ddots&\vdots\\
  > \frac{\part y_1}{\part x_n}&\frac{\part y_2}{\part x_n}&\ldots&\frac{\part y_m}{\part x_n}\\
  > \end{bmatrix}
  > $$

## [矩阵向量求导 微分法](https://blog.csdn.net/xq151750111/article/details/121026066)

假设一个多元函数为$f$
$$
df=\sum_{i=1}^n\frac{\part f}{\part x_i}dx_i
=\begin{bmatrix}
\frac{\part f}{\part x_1}&\frac{\part f}{\part x_2}&\ldots&\frac{\part f}{\part x_n}
\end{bmatrix}
\begin{bmatrix}
dx_1\\
dx_2\\
\ldots\\
dx_n
\end{bmatrix}
=(\frac{\part f}{\part\mathbf x})^Td\mathbf x
$$
由此推广到矩阵
$$
\begin{align}
df&=\sum_{i=1}^m\sum_{j=1}^n\frac{\part f}{\part X_{ij}}dX_{ij}
\end{align}
$$
如何使用矩阵的语言表达出来？我们观察下面两者
$$
(\frac{\part f}{\part\mathbf X})^T=
\begin{bmatrix}
\frac{\part f}{\part X_{11}}&\ldots&\frac{\part f}{\part X_{m1}}\\
\vdots&\ddots&\vdots\\
\frac{\part f}{\part X_{1n}}&\ldots&\frac{\part f}{\part X_{mn}}
\end{bmatrix}\\
d\mathbf X=\begin{bmatrix}
dX_{11}&\ldots&dX_{1n}\\
\vdots&\ddots&\vdots\\
dX_{m1}&\ldots&dX_{mn}
\end{bmatrix}
$$
如果我们将$(\frac{\part f}{\part\mathbf X})^T$以及$d\mathbf X$划分如下
$$
(\frac{\part f}{\part\mathbf X})^T=
\begin{bmatrix}
\alpha_1\\
\vdots\\
\alpha_n
\end{bmatrix}\\
d\mathbf X=\begin{bmatrix}
\beta_1&\ldots&\beta_n
\end{bmatrix}
$$
我们发现$df$实际上等于$\sum_{i=1}^n\alpha_i\beta_i$，也就是$tr((\frac{\part f}{\part\mathbf X})^Td\mathbf X)$

- 矩阵微分中的哈达马积
  $$
  d\sigma(X)=\sigma^{'}(X)\odot dX\\
  tr((A\odot B)^TC)=tr(A^T(B\odot C))
  $$
  

### 迹函数对向量矩阵求导

$$
\frac{\part tr(AB)}{\part A}=B^T,\frac{\part tr(AB)}{\part B}=A^T
$$

## [矩阵向量求导链式法则](https://www.cnblogs.com/pinard/p/10825264.html)

- 向量对向量求导的链式法则

  假设三个向量$\mathbf x\rightarrow\mathbf y\rightarrow\mathbf z$，我们能够有以下链式法则
  $$
  \frac{\part\mathbf z}{\part\mathbf x}=\frac{\part\mathbf z}{\part\mathbf y}\frac{\part\mathbf y}{\part\mathbf x}
  $$
  
  假设向量$\mathbf x,\mathbf y,\mathbf z$的维度为$n, m,p$
  
  我们可以这么理解，$\frac{\part\mathbf z}{\part\mathbf x}$是$p\times n$的雅可比矩阵，$\frac{\part\mathbf z}{\part\mathbf y}$为$p\times m$的雅可比矩阵，$\frac{\part y}{\part x}$为$m\times n$的雅可比矩阵
  
  后面两者实际上能够相乘，得到的形状与等号左边相同
  
- 标量对向量求导的链式法则

  *在链接的教程中，提出了使用转置来解决矩阵不可乘的问题，个人认为实际上教程中对于矩阵乘法的定义存在问题，假设在默认分子布局的情况下，这个问题并不存在*

  假设存在一种依赖关系$\mathbf x\rightarrow\mathbf y\rightarrow z$，如果按照上面的链式法则关系，$\frac{\part z}{\part\mathbf y}$的形状为$1\times m$，$\frac{\part\mathbf y}{\part\mathbf x}$的形状为$m\times n$
  $$
  \frac{\part z}{\part\mathbf x}=\frac{\part z}{\part\mathbf y}\frac{\part\mathbf y}{\part\mathbf x}
  $$
  实际上我们依然能够使用类似向量对向量求导的链式法则

- 标量对多个矩阵的链式法则

  我们假设$A,X,B,Y$都是矩阵，$z$是标量，其中$z=f(Y),Y=AX+B$，现在我们要求出$\frac{\part z}{\part X}$，实际上标量对矩阵求导的链式法则没有确切的定义，我们只能从定义法出发
  $$
  \frac{\part z}{\part x_{ij}}=\sum_{k,l}\frac{\part z}{\part Y_{kl}}\frac{\part Y_{kl}}{\part X_{ij}}
  $$
  具体的求解过程参考链接，答案如下
  $$
  \frac{\part z}{\part X}=A^T\frac{\part z}{\part Y}
  $$
  以下总结四种常用的标量对矩阵求导的公式

  ![2](.\pic\2.png)

## [矩阵对矩阵求导](https://www.cnblogs.com/pinard/p/10930902.html)

因为和机器学习关系不大，因此直接跳过