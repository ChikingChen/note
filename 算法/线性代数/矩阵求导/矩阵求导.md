# [矩阵求导](https://www.cnblogs.com/pinard/p/10750718.html)

## 矩阵向量求导引入

向量对标量的求导，实质上是向量中每个分量分别对标量求导，如下表示
$$
\frac{\part\mathbf{y}}{\part x}
$$
$m$维向量$\mathbf{y}$对标量$x$求导，结果将是一个$m$维向量，这个向量是行向量或者列向量都可以

## 求导布局

为了解决矩阵向量求导不一致的问题，我们引入了求导布局的概念——分子布局和分母布局

- 分子布局

  求导结果的维度以分子为主，如果$\mathbf{y}$是一个列向量，那么的话$\frac{\part\mathbf{y}}{\part x}$的结果也是一个列向量

- 分母布局

  求导结果的维度以分母为主；如果分母是标量，那么就是分子布局的转置

如此我们能够确定**标量对于矩阵或者向量**还有**矩阵或者向量对于标量**求导的情况

接下来是向量对于向量的求导

## [定义法 标量对向量求导](https://www.cnblogs.com/pinard/p/10773942.html)

标量对向量中的每个值分别进行求导

求解$\frac{\part \mathbf x^T\mathbf A\mathbf x}{\part\mathbf x}$

我们对$\mathbf x$的第$k$个分量求导如下
$$
\frac{\part \mathbf x^T\mathbf A\mathbf x}{\part x_k}=\frac{\part\sum_{i=1}^n\sum_{j=1}^nx_iA_{ij}x_j}{\part x_k}=\sum_{i=1}^nA_{ki}x_i+\sum_{i=1}^nA_{ik}x_i
$$
我们将这若干个分量合并
$$
\frac{\part \mathbf x^T\mathbf A\mathbf x}{\part \mathbf x}=\mathbf A\mathbf x+\mathbf A^T\mathbf x
$$

## 定义法 标量对矩阵求导

求解$\frac{\part \mathbf a^T\mathbf X\mathbf b}{\part\mathbf X}$

我们对矩阵$\mathbf X$的元素$\mathbf X_{ij}$求导
$$
\frac{\part \mathbf a^T\mathbf X\mathbf b}{\part X_{ij}}=\frac{\part\sum_{p=1}^{m}\sum_{q=1}^na_pX_{pq}b_q}{X_{ij}}=a_ib_j
$$
因此求导的结果为
$$
\frac{\part \mathbf a^T\mathbf X\mathbf b}{\part\mathbf X}=\mathbf a\mathbf b^T
$$

## 定义法 向量对向量求导

实际上和以上两者相同，将两个向量中的元素两两拿出分别求导，即可得到求导结果

- 向量对向量求导 雅可比矩阵 梯度矩阵

  我们假设存在一个$m$维的列向量$\mathbf y$以及一个$n$维的列向量$\mathbf x$
  $$
  \mathbf x=\begin{bmatrix}
  x_1\\
  x_2\\
  \ldots\\
  x_n
  \end{bmatrix},
  \mathbf y=\begin{bmatrix}
  y_1\\
  y_2\\
  \ldots\\
  y_m
  \end{bmatrix}
  $$
  我们能够使用$\frac{\part\mathbf y}{\part\mathbf x^T}$来定义雅可比矩阵
  $$
  \frac{\part\mathbf y}{\part\mathbf x^T}=\begin{bmatrix}
  \frac{\part y_1}{\part x_1}&\frac{\part y_1}{\part x_x}&\ldots&\frac{\part y_1}{\part x_n}\\
  \frac{\part y_2}{\part x_1}&\frac{\part y_2}{\part x_x}&\ldots&\frac{\part y_2}{\part x_n}\\
  \vdots&\vdots&\ddots&\vdots\\
  \frac{\part y_m}{\part x_1}&\frac{\part y_m}{\part x_x}&\ldots&\frac{\part y_m}{\part x_n}\\
  \end{bmatrix}
  $$
  或者使用$\frac{\part\mathbf y^T}{\part\mathbf x}$来定义梯度矩阵
  $$
  \frac{\part\mathbf y^T}{\part\mathbf x}=\begin{bmatrix}
  \frac{\part y_1}{\part x_1}&\frac{\part y_2}{\part x_1}&\ldots&\frac{\part y_m}{\part x_1}\\
  \frac{\part y_1}{\part x_2}&\frac{\part y_2}{\part x_2}&\ldots&\frac{\part y_m}{\part x_2}\\
  \vdots&\vdots&\ddots&\vdots\\
  \frac{\part y_1}{\part x_n}&\frac{\part y_2}{\part x_n}&\ldots&\frac{\part y_m}{\part x_n}\\
  \end{bmatrix}
  $$
  

## [矩阵向量求导 微分法](https://blog.csdn.net/xq151750111/article/details/121026066)

假设一个多元函数为$f$
$$
df=\sum_{i=1}^n\frac{\part f}{\part x_i}dx_i
=\begin{bmatrix}
\frac{\part f}{\part x_1}&\frac{\part f}{\part x_2}&\ldots&\frac{\part f}{\part x_n}
\end{bmatrix}
\begin{bmatrix}
dx_1\\
dx_2\\
\ldots\\
dx_n
\end{bmatrix}
=(\frac{\part f}{\part\mathbf x})^Td\mathbf x
$$
由此推广到矩阵
$$
\begin{align}
df&=\sum_{i=1}^m\sum_{j=1}^n\frac{\part f}{\part X_{ij}}dX_{ij}
\end{align}
$$
如何使用矩阵的语言表达出来？我们观察下面两者
$$
(\frac{\part f}{\part\mathbf X})^T=
\begin{bmatrix}
\frac{\part f}{\part X_{11}}&\ldots&\frac{\part f}{\part X_{m1}}\\
\vdots&\ddots&\vdots\\
\frac{\part f}{\part X_{1n}}&\ldots&\frac{\part f}{\part X_{mn}}
\end{bmatrix}\\
d\mathbf X=\begin{bmatrix}
dX_{11}&\ldots&dX_{1n}\\
\vdots&\ddots&\vdots\\
dX_{m1}&\ldots&dX_{mn}
\end{bmatrix}
$$
如果我们将$(\frac{\part f}{\part\mathbf X})^T$以及$d\mathbf X$划分如下
$$
(\frac{\part f}{\part\mathbf X})^T=
\begin{bmatrix}
\alpha_1\\
\vdots\\
\alpha_n
\end{bmatrix}\\
d\mathbf X=\begin{bmatrix}
\beta_1&\ldots&\beta_n
\end{bmatrix}
$$
我们发现$df$实际上等于$\sum_{i=1}^n\alpha_i\beta_i$，也就是$tr((\frac{\part f}{\part\mathbf X})^Td\mathbf X)$

- 矩阵微分中的哈达马积
  $$
  d\sigma(X)=\sigma^{'}(X)\odot dX\\
  tr((A\odot B)^TC)=tr(A^T(B\odot C))
  $$
  

### 迹函数对向量矩阵求导

$$
\frac{\part tr(AB)}{\part A}=B^T,\frac{\part tr(AB)}{\part B}=A^T
$$

## 矩阵向量求导链式法则

- 向量对向量求导的链式法则

  假设三个向量$\mathbf x\rightarrow\mathbf y\rightarrow\mathbf z$，我们能够有以下链式法则
  $$
  \frac{\part\mathbf x}{\part\mathbf z}=\frac{\part\mathbf x}{\part\mathbf y}\frac{\part\mathbf y}{\part\mathbf z}
  $$
  