# [深度神经网络](https://zhuanlan.zhihu.com/p/29815081)

## DNN中的具体参数

![pic7](.\pic\pic7.png)

- 线性关系系数$w$的定义，$w_{24}^3$——第2层第4个元素指向第3层第2个元素

  我们直接看第2层到第3层的仿射变换
  $$
  y=wx+b
  $$
  $x$为$4*1$的矩阵，$y$为$2*1$的矩阵，$x$则为$2*4$的矩阵，$2$代表第三层的元素数量，$4$代表第二层的元素数量

![pic8](.\pic\pic8.png)

- 偏置$b$的定义

  $b^2_3$代表第2层第3个元素

## 前向传播的表示

$a^l$为第$l$层的输出，$\sigma$则为激活函数，$z_l$为神经元的计算结果
$$
a^l=\sigma(z^l)=\sigma(W^la^{l-1}+b^l)
$$

## 反向传播算法

我们将神经网络的损失函数定义如下
$$
J(W,b,x,y)=\frac{1}{2}||a^L-y||_2^2
$$
输出层第$L$层，我们认为其$W$和$b$满足一下式子
$$
a^L=\sigma(z^L)=\sigma(W^La^{L-1}+b^L)
$$
因此损失函数即为
$$
J(W,b,x,y)=\frac{1}{2}||a^L-y||_2^2=\frac{1}{2}||\sigma(z^L)-y||_2^2=\frac{1}{2}||\sigma(W^La^{L-1}+b^L)-y||_2^2
$$
求解W,b的梯度：
$$
\begin{cases}
\frac{\part J(W,b,x,y)}{\part W^L}&=\frac{\part J(W,b,x,y)}{\part z^L}\frac{\part z^L}{\part W^L}\\
\frac{\part J(W,b,x,y)}{\part b^L}&=\frac{\part J(W,b,x,y)}{\part z^L}\frac{\part z^L}{\part b^L}
\end{cases}
$$

- $\frac{\part J(W,b,x,y)}{\part z^L}$的计算

  

