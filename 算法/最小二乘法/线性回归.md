# [线性回归](https://zhuanlan.zhihu.com/p/72513104)

我们给出$n$个点$(x_i,y_i)$，然后找到一个近似的线性解$y=\beta_0 x+\beta_1$，这个近似解在预测这$n$个点的时候误差最小

## 如何度量残差

$$
Q=\sum_{i=1}^n(y_i-\hat y_i)^2=\sum_{i=1}^n(y_i-(\hat\beta_0+\hat\beta_1x_i))^2
$$

就是最小二乘估计

我们能够理解的是这里的$x_i$，$y_i$实际上都是已知的，我们需要求解$\hat\beta_0$以及$\hat\beta_1$

![1](.\pic\1.jpg)

我们可以理解的是，关于有两个未知数的方程其实际上的图像如图所示，其本质上是一个凸函数，我们需要求解凸函数的最低点，也就是导数为0的点
$$
\begin{align}
\frac{\part Q}{\part\beta_0}&=2\sum_{i=1}^n(y_i-\hat\beta_0-\hat\beta_1x_i)=0\\
\frac{\part Q}{\part\beta_1}&=2\sum_{i=1}^n(y_i-\hat\beta_0-\hat\beta_1x_i)x_i=0
\end{align}
$$
通过上式求解即可得到

## 多元线性回归

实际上假设$y$变量与多个$x_i$变量呈线性关系就能够将线性回归拓展至多元线性回归

假设$y=\beta_0+\beta_1x_1+\ldots+\beta_px_p$，其余的步骤与上面类似

